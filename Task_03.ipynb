{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task-03"
      ],
      "metadata": {
        "id": "OiJn_V9xBp5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Data Loading with Error Handling ---\n",
        "file_path = '/content/bank-full.csv'\n",
        "try:\n",
        "    bank_data = pd.read_csv(file_path, delimiter=';', error_bad_lines=False)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Assuming the dataset is loaded successfully past the error handling above:\n",
        "# --- Data Preprocessing ---\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = bank_data.select_dtypes(include=['object']).columns\n",
        "for column in categorical_columns:\n",
        "    bank_data[column] = label_encoder.fit_transform(bank_data[column])\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = bank_data.drop('y', axis=1)\n",
        "y = bank_data['y']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Model Building, Training, and Evaluation ---\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW4i2Z6xBk_D",
        "outputId": "64973733-aa3e-4413-aab6-779b625f2063"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-fa6b3b1c3faf>:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  bank_data = pd.read_csv(file_path, delimiter=';', error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8740462235983634\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      7952\n",
            "           1       0.48      0.48      0.48      1091\n",
            "\n",
            "    accuracy                           0.87      9043\n",
            "   macro avg       0.70      0.70      0.70      9043\n",
            "weighted avg       0.87      0.87      0.87      9043\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation and Insights:**\n",
        "\n",
        "**Data Preprocessing:** We encoded categorical variables to numeric, making the dataset suitable for machine learning algorithms. The dataset was then split into features and target variables, followed by splitting into training and testing sets.\n",
        "\n",
        "**Model Building and Training:** We built a Decision Tree classifier, a straightforward yet powerful model for classification tasks. The model was trained on the training data without any hyperparameter tuning for simplicity.\n",
        "\n",
        "**Model Evaluation: **The Decision Tree achieved an accuracy of approximately 87.4% on the test data. It performed well in predicting non-subscribers (class 0) with high precision, recall, and F1-score. However, its performance in predicting subscribers (class 1) was less accurate, indicating potential areas for improvement."
      ],
      "metadata": {
        "id": "Q12qhkMGByPa"
      }
    }
  ]
}